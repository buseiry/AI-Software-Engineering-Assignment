{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8557be7d",
   "metadata": {},
   "source": [
    "# Predictive Analytics: Issue Priority Prediction (Breast Cancer Dataset)\n",
    "\n",
    "This notebook demonstrates a complete workflow to **import**, **clean**, **label**, **split**, and **model** the Kaggle *Breast Cancer Wisconsin (Diagnostic)* dataset to predict **issue priority** (high / medium / low).\n",
    "\n",
    "> ⚠️ Note: The original dataset has a **binary diagnosis** (Malignant vs Benign).  \n",
    "> For this exercise, we derive a 3-class **priority** label using a simple, transparent rule: we first train a small risk model **only on the training set** to estimate malignancy probability; then we **bin** those probabilities into Low / Medium / High using the 33rd and 66th percentiles **computed on the training data**. We finally train a **Random Forest** to predict these priority labels on a held-out test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa8eda",
   "metadata": {},
   "source": [
    "## 0. Environment & Reproducibility\n",
    "\n",
    "- Uses Python, `pandas`, `scikit-learn`.  \n",
    "- Random seeds fixed where applicable.  \n",
    "- The notebook will try to download from **Kaggle** if your Kaggle API is configured; otherwise it will **fall back** to `sklearn.datasets.load_breast_cancer` (same UCI dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Import (Kaggle if available, else sklearn fallback)\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Toggle this to force fallback without touching Kaggle:\n",
    "FORCE_FALLBACK = False\n",
    "\n",
    "def load_data():\n",
    "    # If Kaggle credentials exist and not forcing fallback, try Kaggle\n",
    "    kaggle_creds = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
    "    if (not FORCE_FALLBACK) and os.path.exists(kaggle_creds):\n",
    "        try:\n",
    "            # This dataset is a mirror of the UCI Wisconsin (Diagnostic) data:\n",
    "            # https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "            print(\"Attempting Kaggle download...\")\n",
    "            os.system(\"kaggle datasets download -d uciml/breast-cancer-wisconsin-data -p ./data -q\")\n",
    "            os.makedirs(\"./data\", exist_ok=True)\n",
    "            # Unzip if needed\n",
    "            for fname in os.listdir(\"./data\"):\n",
    "                if fname.endswith(\".zip\"):\n",
    "                    with zipfile.ZipFile(os.path.join(\"./data\", fname), \"r\") as zf:\n",
    "                        zf.extractall(\"./data\")\n",
    "            # Look for CSV\n",
    "            candidates = [f for f in os.listdir(\"./data\") if f.lower().endswith(\".csv\")]\n",
    "            if candidates:\n",
    "                csv_path = os.path.join(\"./data\", candidates[0])\n",
    "                df = pd.read_csv(csv_path)\n",
    "                print(f\"Loaded Kaggle CSV: {csv_path}\")\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            print(\"Kaggle download failed, falling back to sklearn:\", e)\n",
    "\n",
    "    # Fallback to sklearn (UCI) dataset (same content, different packaging)\n",
    "    print(\"Falling back to sklearn.load_breast_cancer\")\n",
    "    sk = load_breast_cancer(as_frame=True)\n",
    "    df = sk.frame.copy()\n",
    "    df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "    # Align naming to Kaggle where possible:\n",
    "    # Kaggle has 'diagnosis' as 'M'/'B'\n",
    "    df['diagnosis'] = df['target'].map({0: 'M', 1: 'B'})\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b0eb4",
   "metadata": {},
   "source": [
    "## 2. Clean & Label\n",
    "\n",
    "- **Cleaning**: standardize column names, drop obvious identifiers if present (e.g., `id`), check nulls.  \n",
    "- **Labeling**: derive **priority** ∈ {`low`, `medium`, `high`} from a *risk proxy* computed *only on the training set*:\n",
    "  1. Split into **train/test** first (to avoid leakage).\n",
    "  2. On **train only**, fit a simple logistic regression (with CV) to obtain malignancy probabilities.\n",
    "  3. Compute **33rd** and **66th** percentile thresholds on these train probabilities.\n",
    "  4. Map probability → priority: `low` (≤ p33), `medium` (p33–p66], `high` (> p66).\n",
    "  5. Apply the **same thresholds** to test-set probabilities produced by the train-fitted model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ee801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Basic cleaning\n",
    "df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "df = df.copy()\n",
    "\n",
    "# Drop an 'id' column if present in Kaggle CSV\n",
    "if 'id' in df.columns:\n",
    "    df = df.drop(columns=['id'])\n",
    "\n",
    "# Ensure 'diagnosis' column exists (Kaggle has 'diagnosis' B/M)\n",
    "if 'diagnosis' not in df.columns and 'target' in df.columns:\n",
    "    df['diagnosis'] = df['target'].map({0:'M', 1:'B'})\n",
    "\n",
    "# Split before deriving priority\n",
    "features = [c for c in df.columns if c not in ('diagnosis','target')]\n",
    "X = df[features]\n",
    "y_diag = df['diagnosis']  # 'M' or 'B'\n",
    "\n",
    "X_train, X_test, y_train_diag, y_test_diag = train_test_split(\n",
    "    X, y_diag, test_size=0.2, random_state=42, stratify=y_diag\n",
    ")\n",
    "\n",
    "# Risk proxy model (train only)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logit = LogisticRegression(max_iter=500)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Out-of-fold probs on TRAIN\n",
    "oof_proba = cross_val_predict(\n",
    "    logit, X_train_scaled, (y_train_diag == 'M').astype(int),\n",
    "    cv=cv, method='predict_proba'\n",
    ")[:, 1]\n",
    "\n",
    "# Fit on all TRAIN, then score TEST\n",
    "logit.fit(X_train_scaled, (y_train_diag == 'M').astype(int))\n",
    "test_proba = logit.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Compute thresholds on TRAIN\n",
    "p33 = np.quantile(oof_proba, 1/3)\n",
    "p66 = np.quantile(oof_proba, 2/3)\n",
    "\n",
    "def to_priority(p):\n",
    "    if p <= p33:\n",
    "        return 'low'\n",
    "    elif p <= p66:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "y_train_pri = pd.Series([to_priority(p) for p in oof_proba], index=X_train.index)\n",
    "y_test_pri = pd.Series([to_priority(p) for p in test_proba], index=X_test.index)\n",
    "\n",
    "# Quick sanity check\n",
    "pd.Series(y_train_pri).value_counts(normalize=True).rename('train_class_mix'), \\\n",
    "pd.Series(y_test_pri).value_counts(normalize=True).rename('test_class_mix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c1839",
   "metadata": {},
   "source": [
    "## 3. Model: Random Forest\n",
    "\n",
    "We fit a **RandomForestClassifier** to predict the 3-class priority on the **training** split and evaluate on the **test** split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef463de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    random_state=42,\n",
    "    class_weight='balanced_subsample'\n",
    ")\n",
    "rf.fit(X_train, y_train_pri)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test_pri, y_pred)\n",
    "f1_macro = f1_score(y_test_pri, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Macro F1:\", f1_macro)\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test_pri, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465c8ab",
   "metadata": {},
   "source": [
    "## 4. Results (Accuracy & F1)\n",
    "\n",
    "Below are the key results captured from a test run:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a6d13",
   "metadata": {},
   "source": [
    "**Key Results (on test set)**  \n",
    "- Accuracy: **0.9035**  \n",
    "- Macro F1-score: **0.9057**\n",
    "\n",
    "<details>\n",
    "<summary>Classification report</summary>\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        high     0.9412    0.9697    0.9552        33\n",
    "         low     0.9500    0.8636    0.9048        44\n",
    "      medium     0.8250    0.8919    0.8571        37\n",
    "\n",
    "    accuracy                         0.9035       114\n",
    "   macro avg     0.9054    0.9084    0.9057       114\n",
    "weighted avg     0.9069    0.9035    0.9039       114\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97ece1",
   "metadata": {},
   "source": [
    "## 5. Notes & Next Steps\n",
    "\n",
    "- The 3-class **priority** is a derived target for demonstration purposes (the source data is binary).  \n",
    "- Consider **calibrated** models and domain-approved thresholds for real triage systems.  \n",
    "- Try alternative models (XGBoost, LightGBM) and perform **hyperparameter tuning**.  \n",
    "- Add **confusion matrix** and **feature importance** plots for more insight.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
