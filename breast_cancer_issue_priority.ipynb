{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8557be7d",
   "metadata": {},
   "source": [
    "# Predictive Analytics: Issue Priority Prediction (Breast Cancer Dataset)\n",
    "\n",
    "This notebook demonstrates a complete workflow to **import**, **clean**, **label**, **split**, and **model** the Kaggle *Breast Cancer Wisconsin (Diagnostic)* dataset to predict **issue priority** (high / medium / low).\n",
    "\n",
    "> ⚠️ Note: The original dataset has a **binary diagnosis** (Malignant vs Benign).  \n",
    "> For this exercise, we derive a 3-class **priority** label using a simple, transparent rule: we first train a small risk model **only on the training set** to estimate malignancy probability; then we **bin** those probabilities into Low / Medium / High using the 33rd and 66th percentiles **computed on the training data**. We finally train a **Random Forest** to predict these priority labels on a held-out test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa8eda",
   "metadata": {},
   "source": [
    "## 0. Environment & Reproducibility\n",
    "\n",
    "- Uses Python, `pandas`, `scikit-learn`.  \n",
    "- Random seeds fixed where applicable.  \n",
    "- The notebook will try to download from **Kaggle** if your Kaggle API is configured; otherwise it will **fall back** to `sklearn.datasets.load_breast_cancer` (same UCI dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0c3741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to sklearn.load_breast_cancer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "      <th>target</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean_fractal_dimension  ...  worst_perimeter  worst_area  worst_smoothness  \\\n",
       "0                 0.07871  ...           184.60      2019.0            0.1622   \n",
       "1                 0.05667  ...           158.80      1956.0            0.1238   \n",
       "2                 0.05999  ...           152.50      1709.0            0.1444   \n",
       "3                 0.09744  ...            98.87       567.7            0.2098   \n",
       "4                 0.05883  ...           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst_compactness  worst_concavity  worst_concave_points  worst_symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst_fractal_dimension  target  diagnosis  \n",
       "0                  0.11890       0          M  \n",
       "1                  0.08902       0          M  \n",
       "2                  0.08758       0          M  \n",
       "3                  0.17300       0          M  \n",
       "4                  0.07678       0          M  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Data Import (Kaggle if available, else sklearn fallback)\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Toggle this to force fallback without touching Kaggle:\n",
    "FORCE_FALLBACK = False\n",
    "\n",
    "def load_data():\n",
    "    # If Kaggle credentials exist and not forcing fallback, try Kaggle\n",
    "    kaggle_creds = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
    "    if (not FORCE_FALLBACK) and os.path.exists(kaggle_creds):\n",
    "        try:\n",
    "            # This dataset is a mirror of the UCI Wisconsin (Diagnostic) data:\n",
    "            # https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "            print(\"Attempting Kaggle download...\")\n",
    "            os.system(\"kaggle datasets download -d uciml/breast-cancer-wisconsin-data -p ./data -q\")\n",
    "            os.makedirs(\"./data\", exist_ok=True)\n",
    "            # Unzip if needed\n",
    "            for fname in os.listdir(\"./data\"):\n",
    "                if fname.endswith(\".zip\"):\n",
    "                    with zipfile.ZipFile(os.path.join(\"./data\", fname), \"r\") as zf:\n",
    "                        zf.extractall(\"./data\")\n",
    "            # Look for CSV\n",
    "            candidates = [f for f in os.listdir(\"./data\") if f.lower().endswith(\".csv\")]\n",
    "            if candidates:\n",
    "                csv_path = os.path.join(\"./data\", candidates[0])\n",
    "                df = pd.read_csv(csv_path)\n",
    "                print(f\"Loaded Kaggle CSV: {csv_path}\")\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            print(\"Kaggle download failed, falling back to sklearn:\", e)\n",
    "\n",
    "    # Fallback to sklearn (UCI) dataset (same content, different packaging)\n",
    "    print(\"Falling back to sklearn.load_breast_cancer\")\n",
    "    sk = load_breast_cancer(as_frame=True)\n",
    "    df = sk.frame.copy()\n",
    "    df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "    # Align naming to Kaggle where possible:\n",
    "    # Kaggle has 'diagnosis' as 'M'/'B'\n",
    "    df['diagnosis'] = df['target'].map({0: 'M', 1: 'B'})\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b0eb4",
   "metadata": {},
   "source": [
    "## 2. Clean & Label\n",
    "\n",
    "- **Cleaning**: standardize column names, drop obvious identifiers if present (e.g., `id`), check nulls.  \n",
    "- **Labeling**: derive **priority** ∈ {`low`, `medium`, `high`} from a *risk proxy* computed *only on the training set*:\n",
    "  1. Split into **train/test** first (to avoid leakage).\n",
    "  2. On **train only**, fit a simple logistic regression (with CV) to obtain malignancy probabilities.\n",
    "  3. Compute **33rd** and **66th** percentile thresholds on these train probabilities.\n",
    "  4. Map probability → priority: `low` (≤ p33), `medium` (p33–p66], `high` (> p66).\n",
    "  5. Apply the **same thresholds** to test-set probabilities produced by the train-fitted model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ee801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(high      0.334066\n",
       " low       0.334066\n",
       " medium    0.331868\n",
       " Name: train_class_mix, dtype: float64,\n",
       " low       0.385965\n",
       " medium    0.324561\n",
       " high      0.289474\n",
       " Name: test_class_mix, dtype: float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Basic cleaning\n",
    "df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "df = df.copy()\n",
    "\n",
    "# Drop an 'id' column if present in Kaggle CSV\n",
    "if 'id' in df.columns:\n",
    "    df = df.drop(columns=['id'])\n",
    "\n",
    "# Ensure 'diagnosis' column exists (Kaggle has 'diagnosis' B/M)\n",
    "if 'diagnosis' not in df.columns and 'target' in df.columns:\n",
    "    df['diagnosis'] = df['target'].map({0:'M', 1:'B'})\n",
    "\n",
    "# Split before deriving priority\n",
    "features = [c for c in df.columns if c not in ('diagnosis','target')]\n",
    "X = df[features]\n",
    "y_diag = df['diagnosis']  # 'M' or 'B'\n",
    "\n",
    "X_train, X_test, y_train_diag, y_test_diag = train_test_split(\n",
    "    X, y_diag, test_size=0.2, random_state=42, stratify=y_diag\n",
    ")\n",
    "\n",
    "# Risk proxy model (train only)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logit = LogisticRegression(max_iter=500)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Out-of-fold probs on TRAIN\n",
    "# cross_val_predict with method='predict_proba' can sometimes return a 2D array\n",
    "# (n_samples, n_classes). Be defensive: extract the column corresponding to\n",
    "# the positive class (here class '1' meaning diagnosis == 'M').\n",
    "oof_raw = cross_val_predict(\n",
    "    logit, X_train_scaled, (y_train_diag == 'M').astype(int),\n",
    "    cv=cv, method='predict_proba'\n",
    ")\n",
    "\n",
    "if oof_raw.ndim == 1:\n",
    "    oof_proba = oof_raw.astype(float)\n",
    "else:\n",
    "    # If there are two columns, take the probability for class 1 (positive)\n",
    "    # otherwise take the single column available.\n",
    "    oof_proba = oof_raw[:, 1] if oof_raw.shape[1] > 1 else oof_raw[:, 0]\n",
    "\n",
    "# Fit on all TRAIN, then score TEST\n",
    "logit.fit(X_train_scaled, (y_train_diag == 'M').astype(int))\n",
    "test_raw = logit.predict_proba(X_test_scaled)\n",
    "\n",
    "if test_raw.ndim == 1:\n",
    "    test_proba = test_raw.astype(float)\n",
    "else:\n",
    "    test_proba = test_raw[:, 1] if test_raw.shape[1] > 1 else test_raw[:, 0]\n",
    "\n",
    "# Compute thresholds on TRAIN (use nan-aware quantile just in case)\n",
    "p33 = np.nanpercentile(oof_proba, 33.333)\n",
    "p66 = np.nanpercentile(oof_proba, 66.666)\n",
    "\n",
    "def to_priority(p):\n",
    "    if p <= p33:\n",
    "        return 'low'\n",
    "    elif p <= p66:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "y_train_pri = pd.Series([to_priority(p) for p in oof_proba], index=X_train.index)\n",
    "y_test_pri = pd.Series([to_priority(p) for p in test_proba], index=X_test.index)\n",
    "\n",
    "# Quick sanity check — print counts so the cell output is clear and won't silently create a tuple\n",
    "print(pd.Series(y_train_pri).value_counts(normalize=True).rename('train_class_mix'))\n",
    "print(pd.Series(y_test_pri).value_counts(normalize=True).rename('test_class_mix'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c1839",
   "metadata": {},
   "source": [
    "## 3. Model: Random Forest\n",
    "\n",
    "We fit a **RandomForestClassifier** to predict the 3-class priority on the **training** split and evaluate on the **test** split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef463de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9035087719298246\n",
      "Macro F1: 0.9057095475005923\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        high     0.9412    0.9697    0.9552        33\n",
      "         low     0.9500    0.8636    0.9048        44\n",
      "      medium     0.8250    0.8919    0.8571        37\n",
      "\n",
      "    accuracy                         0.9035       114\n",
      "   macro avg     0.9054    0.9084    0.9057       114\n",
      "weighted avg     0.9069    0.9035    0.9039       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    random_state=42,\n",
    "    class_weight='balanced_subsample'\n",
    ")\n",
    "rf.fit(X_train_scaled, y_train_pri)\\n\n",
    "y_pred = rf.predict(X_test_scaled)\\n\n",
    "acc = accuracy_score(y_test_pri, y_pred)\n",
    "f1_macro = f1_score(y_test_pri, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Macro F1:\", f1_macro)\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test_pri, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465c8ab",
   "metadata": {},
   "source": [
    "## 4. Results (Accuracy & F1)\n",
    "\n",
    "Below are the key results captured from a test run:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a6d13",
   "metadata": {},
   "source": [
    "**Key Results (on test set)**  \n",
    "- Accuracy: **0.9035**  \n",
    "- Macro F1-score: **0.9057**\n",
    "\n",
    "<details>\n",
    "<summary>Classification report</summary>\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        high     0.9412    0.9697    0.9552        33\n",
    "         low     0.9500    0.8636    0.9048        44\n",
    "      medium     0.8250    0.8919    0.8571        37\n",
    "\n",
    "    accuracy                         0.9035       114\n",
    "   macro avg     0.9054    0.9084    0.9057       114\n",
    "weighted avg     0.9069    0.9035    0.9039       114\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97ece1",
   "metadata": {},
   "source": [
    "## 5. Notes & Next Steps\n",
    "\n",
    "- The 3-class **priority** is a derived target for demonstration purposes (the source data is binary).  \n",
    "- Consider **calibrated** models and domain-approved thresholds for real triage systems.  \n",
    "- Try alternative models (XGBoost, LightGBM) and perform **hyperparameter tuning**.  \n",
    "- Add **confusion matrix** and **feature importance** plots for more insight.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
